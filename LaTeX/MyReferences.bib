
@article{rao_making_2020,
	title = {On {Making} {Valid} {Inferences} by {Integrating} {Data} from {Surveys} and {Other} {Sources}},
	issn = {09768394},
	doi = {10.1007/s13571-020-00227-w},
	abstract = {Survey samplers have long been using probability samples from one or more sources in conjunction with census and administrative data to make valid and efficient inferences on finite population parameters. This topic has received a lot of attention more recently in the context of data from non-probability samples such as transaction data, web surveys and social media data. In this paper, I will provide a brief overview of probability sampling methods first and then discuss some recent methods, based on models for the non-probability samples, which could lead to useful inferences from a non-probability sample by itself or when combined with a probability sample. I will also explain how big data may be used as predictors in small area estimation, a topic of current interest because of the growing demand for reliable local area statistics.},
	number = {1934},
	journal = {Sankhya B},
	author = {Rao, J. N.K.},
	year = {2020},
	note = {Publisher: Sankhya B},
	keywords = {Big data, Dual frames, Non-probability sampling, Probability sampling, Sample selection bias, Small area estimation},
	pages = {1--31},
}

@article{beaumont_jean-francois_ask_2021,
	title = {Ask the {Experts}},
	volume = {83},
	issn = {15244725},
	doi = {10.1111/j.1524-4725.1976.tb00178.x},
	abstract = {There is a growing interest in National Statistical Offices to produce Official Statistics using non- probability sample data, such as big data or data from a volunteer web survey, either alone or in combination with probability sample data. The main motivation for using non-probability samples is their low cost and respondent burden, and quick turnaround since they allow for producing estimates shortly after the information needs have been identified. However, non-probability samples are not a panacea. They are well known to produce estimates that may be fraught with significant selection bias. We first discuss this important limitation, along with an illustration, and then describe some remedies through inverse probability weighting or mass imputation. We also discuss how to integrate data from probability and non-probability samples through the Fay-Herriot model used in Small Area Estimation. We conclude with a few remarks on some challenges that statisticians are facing when implementing data integration methods.},
	journal = {The Survey Statistician},
	author = {Beaumont Jean-Francois, Rao J. N. K.},
	year = {2021},
	keywords = {big data, inverse probability weighting, mass imputation, selection bias, small area},
	pages = {11--22},
}

@book{sarndal_model_1992,
	address = {New York,  NY,  US},
	series = {Springer series in statistics.},
	title = {Model assisted survey sampling.},
	isbn = {0-387-97528-4 (Hardcover); 3-540-97528-4 (Hardcover)},
	abstract = {This text on survey sampling contains both basic and advanced material. The main theme is estimation in surveys. . . . This book has four important objectives: 1. To develop the central ideas in survey sampling from the unified perspective of unequal probability sampling. In a majority of surveys, the sampling units have different probabilities of selection, and these probabilities play a crucial role in estimation. 2. To write a basic sampling text that, unlike its predecessors, is guided by statistical modeling in the derivation of estimators. The model assisted approach in this book clarifies and systemizes the use of auxiliary variables, which is an important feature of survey design. 3. To cover significant recent developments in special areas such as analysis of survey data, domain estimation, variance estimation, methods for non-response, and measurement error models. 4. To provide opportunity for students to practice sampling techniques on real data. We provide numerous exercises concerning estimation for real (albeit small) populations described in the appendices.  This book will be useful in teaching basic, as well as more advanced, university courses in survey sampling. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Springer-Verlag Publishing},
	author = {S{\"a}rndal, Carl-Erik and Swensson, Bengt and Wretman, Jan},
	year = {1992},
	doi = {10.1007/978-1-4612-4378-6},
	keywords = {*Sampling (Experimental), *Statistical Estimation, *Surveys, Error Analysis, Experimental Design, Statistical Analysis},
}


@article{sakshaug_sequential_2019,
	title = {Do {Sequential} {Mixed}-{Mode} {Surveys} {Decrease} {Nonresponse} {Bias}, {Measurement} {Error} {Bias}, and {Total} {Bias}? {An} {Experimental} {Study}},
	volume = {7},
	issn = {23250992},
	doi = {10.1093/jssam/smy024},
	abstract = {Mixing multiple modes of survey data collection has become standard practice in survey research. Mixed-mode surveys are faced with a slew of design decisions regarding which types of modes to administer and which sequence to administer them in. Such decisions are largely based on administrative objectives, such as minimizing costs and maximizing response rates. However, just as important to these mixed-mode decisions is their impact on nonresponse bias, measurement error bias, and total bias, which are understudied issues in the mixed-mode literature. In this article, we report on a sequential mixed-mode experiment of young adult drivers randomized to one of two mode sequences: an interviewer-administered (telephone) mode with self-administered (mail) follow-up, or the reverse sequence. Using a mix of direct and indirect bias estimation strategies, we find support for the notion that implementing a second mode of data collection can reduce nonresponse and measurement error bias, but the sequence in which the modes are administered makes a difference: the mail-telephone sequence minimizes bias to a greater extent than the telephone-mail sequence, relative to the starting mode and overall. However, a backfiring effect was found: despite reducing both nonresponse and measurement error bias, switching from mail to telephone increased the total bias in a key estimate of traffic accidents. A discussion of these findings and their implications for survey practice are provided in conclusion.},
	number = {4},
	journal = {Journal of Survey Statistics and Methodology},
	author = {Sakshaug, Joseph W. and Cernat, Alexandru and Raghunathan, Trivellore E.},
	year = {2019},
	keywords = {Auxiliary data, Data collection, Mail survey, Telephone survey, Total survey error},
	pages = {545--571},
	file = {Sakshaug, Cernat, Raghunathan - 2019 - Do Sequential Mixed-Mode Surveys Decrease Nonresponse Bias, Measurement Error Bias, and Total Bia.pdf:C\:\\/Users/valaste/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sakshaug, Cernat, Raghunathan - 2019 - Do Sequential Mixed-Mode Surveys Decrease Nonresponse Bias, Measurement Error Bias, and Total Bia.pdf:application/pdf},
}

@article{schork_survey_2021,
	title = {Survey {Mode} {Effects} on {Objective} and {Subjective} {Questions}: {Evidence} from the {Labour} {Force} {Survey}},
	volume = {37},
	issn = {20017367},
	doi = {10.2478/jos-2021-0009},
	abstract = {Web questionnaires are increasingly used to complement traditional data collection in mixed mode surveys. However, the utilization of web data raises concerns whether web questionnaires lead to mode-specific measurement bias. We argue that the magnitude of measurement bias strongly depends on the content of a variable. Based on the Luxembourgish Labour Force Survey, we investigate differences between web and telephone data in terms of objective (i.e., Employment Status) and subjective (i.e., Wage Adequacy and Job Satisfaction) variables. To assess whether differences in outcome variables are caused by sample composition or mode-specific measurement bias, we apply a coarsened exact matching that approximates randomized experiments by reducing dissimilarities between web and telephone samples. We select matching variables with a combination of automatic variable selection via random forest and a literature-driven selection. The results show that objective variables are not affected by mode-specific measurement bias, but web participants report lower satisfaction-levels on subjective variables than telephone participants. Extensive supplementary analyses confirm our results. The present study supports the view that the impact of survey mode depends on the content of a survey and its variables.},
	number = {1},
	journal = {Journal of Official Statistics},
	author = {Schork, Joachim and Riillo, Cesare A.F. and Neumayr, Johann},
	year = {2021},
	keywords = {Web survey, coarsened exact matching, measurement bias, mode effects, telephone survey},
	pages = {213--237},
	file = {Schork, Riillo, Neumayr - 2021 - Survey Mode Effects on Objective and Subjective Questions Evidence from the Labour Force Survey.pdf:C\:\\/Users/valaste/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schork, Riillo, Neumayr - 2021 - Survey Mode Effects on Objective and Subjective Questions Evidence from the Labour Force Survey.pdf:application/pdf},
}

@techreport{bethlehem_article_2009,
	title = {Article {Indicators} for the {Representativeness} of {Survey} {Response} {Indicators} for the {Representativeness} of {Survey} {Response}},
	url = {www.r-indicator.eu.},
	abstract = {Many survey organizations use the response rate as an indicator for the quality of survey data. As a consequence, a variety of measures are implemented to reduce non-response or to maintain response at an acceptable level. However, the response rate is not necessarily a good indicator of non-response bias. A higher response rate does not imply smaller non-response bias. What matters is how the composition of the response differs from the composition of the sample as a whole. This paper describes the concept of R-indicators to assess potential differences between the sample and the response. Such indicators may facilitate analysis of survey response over time, between various fieldwork strategies or data collection modes. Some practical examples are given.},
	author = {Bethlehem, Jelke and Cobben, Fannie and Schouten, Barry},
	year = {2009},
	keywords = {Indicators, Missing data, Non-response, Representativity, Survey quality},
	file = {Bethlehem, Cobben, Schouten - 2009 - Article Indicators for the Representativeness of Survey Response Indicators for the Representativen.pdf:C\:\\/Users/valaste/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bethlehem, Cobben, Schouten - 2009 - Article Indicators for the Representativeness of Survey Response Indicators for the Representativen.pdf:application/pdf},
}



